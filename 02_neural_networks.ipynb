{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creative machine learning - Neural networks\n",
    "\n",
    "### Author: Philippe Esling (esling@ircam.fr)\n",
    "\n",
    "In this course we will cover\n",
    "1. A [quick introduction](#intro) on the principles of neural networks\n",
    "2. An implementation for a [single neuron](#neuron) in Numpy and JAX.\n",
    "3. An exercise on [multi-layer perceptron (MLP)](#mlp) through manual derivation.\n",
    "4. An introduction on [using Pytorch](#pytorch) for defining networks\n",
    "5. An exercise on [audio classification](#audio) using an MLP with Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introducing neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will cover more advanced models known as *neural networks*. The tutorial starts by performing a simple **single neuron** discrimination of two random distributions. We will exhibit the manual implementation using Numpy, and then simplify it with JAX. Then, we will study the typical **XOR problem** by using a more advanced 2-layer **perceptron**. Finally, we generalize the use of neural networks in order to perform classification on a given set of audio files, using the PyTorch library, which will provide simplified implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use relatively _low-level_ libraries to perform the first exercises (implementing your own neurons). To observe this idea in simple setups, we are going to use the `numpy` library and also initialize the homemade course library `cml` and style for future plotting and exercise. We also set the random generator to a fixed point with `rng = np.random.RandomState(1)`, to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"bdf2211f-560b-4d1a-8370-ae106490b738\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"bdf2211f-560b-4d1a-8370-ae106490b738\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ace.js\", \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-language_tools.js\", \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-modelist.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\", \"https://unpkg.com/@holoviz/panel@1.1.0/dist/panel.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"bdf2211f-560b-4d1a-8370-ae106490b738\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.1.1'.replace('rc', '-rc.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'ace': '//cdnjs.cloudflare.com/ajax/libs/ace/1.4.7', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'ace/ext-language_tools': {'deps': ['ace/ace']}, 'ace/ext-modelist': {'deps': ['ace/ace']}, 'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"ace/ace\"], function(ace) {\n\twindow.ace = ace\n\ton_load()\n      })\n      require([\"ace/ext-language_tools\"], function() {\n\ton_load()\n      })\n      require([\"ace/ext-modelist\"], function() {\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 12;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['ace'] !== undefined) && (!(window['ace'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ace.js', 'https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-language_tools.js', 'https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-modelist.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ace.js\", \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-language_tools.js\", \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-modelist.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.1.0/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"/*\\n ~ CML // Creative Machine Learning ~\\n mml.css : CSS styling information for Panel and Bokeh\\n \\n This file defines the main CSS styling information for the CML course\\n \\n Author               :  Philippe Esling\\n                        <esling@ircam.fr>\\n*/\\n\\nbody {\\n  display: flex;\\n  height: 100vh;\\n  margin: 0px;\\n  overflow-x: hidden;\\n  overflow-y: hidden;\\n}\\n\\n.bk-root .bk, .bk-root .bk:before, .bk-root .bk:after {\\n  font-family: \\\"Josefin Sans\\\";\\n}\\n\\nimg {\\n  max-width: 100%;\\n}\\n\\n#container {\\n  padding:0px;\\n  height:100vh;\\n  width: 100vw;\\n  max-width: 100vw;\\n}\\n\\n#sidebar .mdc-list {\\n  padding-left: 5px;\\n  padding-right: 5px;\\n}\\n\\n.mdc-drawer-app-content {\\n  flex: auto;\\n  position: relative;\\n  overflow: hidden;\\n}\\n\\n.mdc-drawer {\\n  background: #FAFAFA; /* GRAY 50 */\\n}\\n\\n.mdc-drawer-app-content {\\n  margin-left: 0 !important;\\n}\\n\\n.title-bar {\\n  display: contents;\\n  justify-content: center;\\n  align-content: center;\\n  width: 100%;\\n}\\n\\n.mdc-top-app-bar .bk-menu {\\n  color: black\\n}\\n\\n.app-header {\\n  display: contents;\\n  padding-left: 10px;\\n  font-size: 1.25em;\\n}\\n\\nimg.app-logo {\\n  padding-right: 10px;\\n  font-size: 28px;\\n  height: 30px;\\n  max-width: inherit;\\n  padding-top: 12px;\\n  padding-bottom: 6px;\\n}\\n\\n#app-title {\\n  padding-right: 12px;\\n  padding-left: 12px;\\n}\\n\\n.title {\\n  font-family: \\\"Josefin Sans\\\";\\n  color: #fff;\\n  text-decoration: none;\\n  text-decoration-line: none;\\n  text-decoration-style: initial;\\n  text-decoration-color: initial;\\n  font-weight: 400;\\n  font-size: 2em;\\n  line-height: 2em;\\n  white-space: nowrap;\\n}\\n\\n.main-content {\\n  overflow-y: scroll;\\n  overflow-x: auto;\\n}\\n\\n#header {\\n  position: absolute;\\n  z-index: 7;\\n}\\n\\n#header-items {\\n  width: 100%;\\n  margin-left:15px;\\n}\\n\\n.pn-busy-container {\\n  align-items: center;\\n  justify-content: center;\\n  display: flex;\\n}\\n\\n.mdc-drawer__content {\\n  overflow-x: hidden;\\n}\\n.mdc-drawer__content, .main-content {\\n  padding: 12px;\\n}\\n\\n.main-content {\\n  height: calc(100vh - 88px);\\n  max-height: calc(100vh - 88px);\\n  padding-right: 32px;\\n}\\n\\nbutton.mdc-button.mdc-card-button {\\n  color: transparent;\\n  height: 50px;\\n}\\n\\np.mdc-button {\\n  display: none;\\n}\\n\\ndiv.mdc-card {\\n  border-radius: 0px\\n}\\n\\n.mdc-card .card-header {\\n  display: flex;\\n}\\n\\n.mdc-card-title {\\n  font-family: \\\"Josefin Sans\\\";\\n  font-weight: bold;\\n  align-items: center;\\n  display: flex !important;\\n  position: relative !important;\\n}\\n\\n.mdc-card-title:nth-child(2) {\\n  margin-left: -1.4em;\\n}\\n\\n.pn-modal {\\n  overflow-y: scroll;\\n  width: 100%;\\n  display: none;\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n}\\n\\n.pn-modal-content {\\n  font-family: \\\"Josefin Sans\\\";\\n  background-color: #0e0e0e;\\n  margin: auto;\\n  margin-top: 25px;\\n  margin-bottom: 25px;\\n  padding: 15px 20px 20px 20px;\\n  border: 1px solid #888;\\n  width: 80% !important;\\n}\\n\\n.pn-modal-close {\\n  position: absolute;\\n  right: 25px;\\n  z-index: 100;\\n}\\n\\n.pn-modal-close:hover,\\n.pn-modal-close:focus {\\n  color: #000;\\n  text-decoration: none;\\n  cursor: pointer;\\n}\\n\\n.custom_button_bokeh button.bk-btn.bk-btn-default {\\n    font-size:48pt;\\n    background-color: #05b7ff;\\n    border-color: #05b7ff;\\n}\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(> .cell-output-ipywidget-background\n",
       "    > .lm-Widget\n",
       "    > *[data-root-id]),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='308fbd66-5c22-4f2c-b9ba-9bcf2bcbafb4'>\n",
       "  <div id=\"ad08f232-828e-4da2-8c53-4879c50ed1eb\" data-root-id=\"308fbd66-5c22-4f2c-b9ba-9bcf2bcbafb4\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"49ecb9bb-7c1f-49d5-8ab2-e1b79fef8684\":{\"version\":\"3.1.1\",\"title\":\"Bokeh Application\",\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}],\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"308fbd66-5c22-4f2c-b9ba-9bcf2bcbafb4\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"8eb90467-c996-4e3f-9997-fc26ee9625d0\",\"attributes\":{\"plot_id\":\"308fbd66-5c22-4f2c-b9ba-9bcf2bcbafb4\",\"comm_id\":\"04af13c0ab8744c286db4d4d71e69f77\",\"client_comm_id\":\"38e672c83dde4f3abfc5dbc5d8b6c7c6\"}}],\"callbacks\":{\"type\":\"map\"}}};\n",
       "  var render_items = [{\"docid\":\"49ecb9bb-7c1f-49d5-8ab2-e1b79fef8684\",\"roots\":{\"308fbd66-5c22-4f2c-b9ba-9bcf2bcbafb4\":\"ad08f232-828e-4da2-8c53-4879c50ed1eb\"},\"root_ids\":[\"308fbd66-5c22-4f2c-b9ba-9bcf2bcbafb4\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "308fbd66-5c22-4f2c-b9ba-9bcf2bcbafb4"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Base imports\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cml.plot import initialize_bokeh\n",
    "from cml.panel import initialize_panel\n",
    "from jupyterthemes.stylefx import set_nb_theme\n",
    "from bokeh.io import show\n",
    "initialize_bokeh()\n",
    "initialize_panel()\n",
    "set_nb_theme(\"onedork\")\n",
    "rng = np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, to simplify your work, we provide sets of functions that allows fast problem definition and plotting functionnalities (from our `cml` library).\n",
    "\n",
    "  |**File**|*Explanation*|\n",
    "  |-------:|:---------|\n",
    "  |`scatter_boundary`|Plots the decision boundary of a single neuron with 2-dimensional inputs|\n",
    "  |`scatter_classes`|Plots (bi-dimensionnal) input patterns|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cml.plot import scatter_classes, scatter_boundary, center_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that a single neuron is only able to learn _linearly separable_ problems. To produce such classes of problems, we provide a script that draw a set of random 2-dimensional points, then choose a random line in this space that will act as the linear frontier between 2 classes (hence defining a linear 2-class problem). The variables that will be used by your code are the following.  \n",
    "\n",
    "```Python\n",
    "y_class       # classes of the observqtions \n",
    "x_inputs      # 2 x n final matrix of random input observations\n",
    "weights       # 2 x 1 vector of neuron weights\n",
    "bias          # 1 x 1 vector of bias\n",
    "```\n",
    "\n",
    "You can execute the code below to see our simple classification problem. (Note that running the same cell multiple times produces a different starting dataset). In order to have a well-defined classification problem, we can rely on the `make_blobs` function provided by `scikit-learn` in the `sklearn.datasets` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b95c5dac90449a18a1ba4fb7955469f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'09e12634-9a57-4a6c-a4da-d8014c528423': {'version"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "# Properties of the problem\n",
    "n_observations = 200\n",
    "noise = 0.2\n",
    "c1_center = [-2, -1]\n",
    "c2_center = [2, 1]\n",
    "# Create points\n",
    "x_coords, y_class = make_blobs(n_samples=n_observations, centers=[c1_center, c2_center], n_features=2, cluster_std=0.55)\n",
    "x_inputs = x_coords + (noise * np.random.randn(n_observations, 2))\n",
    "# Plot the corresponding pattern\n",
    "plot = center_plot(scatter_classes(x_inputs, y_class))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous example does not allow us to know the exact values (slope and bias) of our ground truth separation line. Hence, we can define a more complex separation problem (with points laying almost right on the separation fronteer), but with known values for our ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db0565a953449ce839d5178c4d324a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'bc9b2683-043a-419c-860a-9c56d17ec684': {'version"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of points to generate\n",
    "n_observations = 100;\n",
    "# Generate 2-dimensional random points\n",
    "x_inputs = np.random.rand(int(n_observations), 2) * 2 - 1;\n",
    "# Slope of separating line\n",
    "sep_slope = np.log(np.random.rand() * 10);\n",
    "sep_bias = np.random.rand() * 2 - 1;\n",
    "# Create the indexes for a two-class problem\n",
    "y_class = (x_inputs[:, 1] - x_inputs[:, 0] * sep_slope - sep_bias > 0) * 1;\n",
    "# Plot the corresponding pattern\n",
    "plot = center_plot(scatter_classes(x_inputs, y_class))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"neuron\"></a>\n",
    "## Single neuron\n",
    "\n",
    "For the first parts of the tutorial, we will perform the simplest classification model possible in a neural network setting, a single neuron. We briefly recall here that; given an input vector $ \\mathbf{x} \\in \\mathbb{R}^{n} $, a single neuron computes the function  \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\bar{y}=\\phi\\left(\\sum_{i = 1}^{n}w_{i}.x_{i} + b\\right)\n",
    "\\label{eq1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "with $ \\mathbf{w} \\in \\mathbb{R}^{n} $ a weight vector, $ b $ a bias and $ \\phi\\left( \\cdot \\right) $ an *activation function*. Therefore, if we consider the *threshold* activation function ($ \\mathbb{I}_{0}\\left(x\\right)=1 $ if $ x \\geq 0$), a single neuron simply performs an *affine transform* and then a *linear* discrimination of the space. \n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #410819; border-color: #cb2e47\">\n",
    "\n",
    "> **Important note**\n",
    "> The following implementation tries to remain as close as possible to the original neuron model by McCulloch & Pitts, notably by using the _threshold activation_ function. Although this leads to a very simple implementation (akin to using an _identity_ activation, note that it is not to be used afterwards.\n",
    "\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "As we will see later on, a **neural network** will simply be composed of _layers_ of these neurons, which produce successive computations\n",
    "\n",
    "<img src=\"images/02_feedforward_nn.png\" align=\"center\"/>\n",
    "\n",
    "Geometrically, a single neuron computes an hyperplane that separates the space. In order to learn, we have to adjust the weights and know \"how much wrong we are\". To do so, we consider that we know the desired output $ y_{j} $ of a system for a given example $ \\mathbf{x}_{j} $ (eg. a predicted value for a regression system, a class value for a classification system). Therefore, we define the MSE loss function $ \\mathcal{L}_{\\mathcal{D}} $ over a whole dataset as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_{\\mathcal{D}}=\\sum_{j=1}^{|\\mathcal{D}|}\\left\\Vert \\bar{y}_{j}-y_{j}\\right\\Vert ^{2}\n",
    "\\label{eq2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "with $|\\mathcal{D}|$ being the size of our dataset. In order to know how to change the weights based on the value of the errors, we need to now \"how to change it to make it better\". Therefore, we should compute the sets of derivatives of the error given each parameter\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\Delta\\bar{\\mathbf{w}}=\\left(\\frac{\\delta\\mathcal{L}_{\\mathcal{D}}}{\\delta w_{1}},\\ldots,\\frac{\\delta\\mathcal{L}_{\\mathcal{D}}}{\\delta w_{n}}\\right)\n",
    "\\label{eq3}\n",
    "\\end{equation}\n",
    "$$ \n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Exercise (course)\n",
    ">   1. Perform the derivatives of the output given a single neuron\n",
    ">   2. Perform the derivatives for the bias as well\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your own neuron\n",
    "\n",
    "We will start by training a single neuron to learn how to perform this discrimination with a linear problem (so that a single neuron is enough to solve it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "eta = 1e-2;\n",
    "# Weight decay\n",
    "lambda_r = 0.1\n",
    "# Number of epochs\n",
    "n_epochs = 50\n",
    "# Initialize the weights\n",
    "weights = np.random.randn(1, 2);\n",
    "bias = np.random.randn(1, 1);\n",
    "# Save the weight history for plotting\n",
    "weights_history = np.zeros((n_epochs + 1, 2));\n",
    "bias_history = np.zeros((n_epochs + 1, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to update the following code loop to ensure that your neuron learns to separate between the classes \n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Exercise (course)\n",
    ">   1. Update the loop so that it computes the forward propagation error\n",
    ">   2. Update the loop to perform learning (based on back-propagation)\n",
    ">   3. Run the learning procedure, which should produce a result similar to that displayed on the website\n",
    ">   4. Perform multiple re-runs by **tweaking the hyperparameters** (learning rate, weight decay)\n",
    ">   5. What observations can you make on the learning process?\n",
    ">   6. (Optional) Change the input patterns, and confirm your observations.\n",
    ">   6. (Optional) Incorporate the bias in the weights to obtain a **vectorized** code.\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7004b41c0c4716be1719eafb42293a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'8ba71d87-0fd1-469d-bd7a-ad9ccfa689bb': {'version"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose = False\n",
    "weights_history[0] = weights\n",
    "bias_history[0] = bias\n",
    "# Update loop\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    # Solution  \n",
    "    y_bar = np.dot(weights, x_inputs.T) + bias > 0\n",
    "    if np.sum(np.abs(y_bar - y_class)) == 0:\n",
    "        break\n",
    "    error = y_class - y_bar\n",
    "    weights = weights + eta * (np.dot(error, x_inputs))\n",
    "    bias = bias + eta * (np.sum(error))\n",
    "    ######################\n",
    "    \n",
    "    weights_history[i + 1] = weights\n",
    "    bias_history[i + 1] = bias\n",
    "    \n",
    "    if (verbose):\n",
    "        print('%2d. error = %f, weights = %f, %f, %f' % (i, np.sum(np.abs(error)) / n_observations, bias[0, 0], weights[0, 0], weights[0, 1]))\n",
    "plot = center_plot(scatter_boundary(x_inputs, y_class, weights_history, bias_history, i + 1))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron implementation in `JAX`\n",
    "\n",
    "As seen in the previous course, the `NumPy` implementation requires us to perform manual differentiation of our loss function to understand how to update the parameters. However, the recent [`JAX`](https://github.com/google/jax) library provides **automatic differentiation** on top of the `NumPy` library. If you have not yet completed the set of [tutorials](https://jax.readthedocs.io/en/latest/), we strongly encourage you to do so. We will introduce a few more functions compared to last time, but we try to keep the implementation as simple as possible on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "key = random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep our previousmy generated dataset but we will rely on `jnp.ndarray` instead of `np.ndarray`, by simply casting the arrays to JAX-compliant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jax = jnp.asarray(x_inputs)\n",
    "y_jax = jnp.asarray(y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also keep the same hyperparameters as previously (see `eta`, `lambda_r` and `n_epochs` above) and randomly initialize our parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01\n",
    "# Perform key splitting\n",
    "key_w, key_b, key = random.split(key, 3)\n",
    "# Initialize the weights\n",
    "weights = random.normal(key_w, (1, 2));\n",
    "bias = random.normal(key_b, (1, 1));\n",
    "# Save the weight history for plotting\n",
    "weights_history = jnp.zeros((n_epochs + 1, 2));\n",
    "bias_history = jnp.zeros((n_epochs + 1, 1));\n",
    "# Record the first \n",
    "weights_history = weights_history.at[0].set(weights[0])\n",
    "bias_history = bias_history.at[0].set(bias[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed earlier, the original model by McCulloch & Pitts has several issues regarding its use for numerical optimization (as it was originally observed from a neuroscience point of view)\n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #410819; border-color: #cb2e47\">\n",
    "\n",
    "> **Changes from the `NumPy` implementation**\n",
    ">   1. (Smoothness) Our _activation function_ will change from _identity_ to sigmoid, i.e. $ \\phi(\\mathbf{x}) = \\frac{1}{1 + e^{-\\mathbf{x}}} $\n",
    ">   2. (Outliers) Our _loss function_ will change from $ L_{1} $ to $ L_{2} $ (MSE - Mean Squared Error)\n",
    "\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "As discussed in the previous course, for using the very handy `grad` function provided by `JAX`, we need to define the whole forward function that we want to derive given our parameters. Hence this function also needs to **contain the forward pass**. This is summarized in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "# Single neuron full function\n",
    "def loss_function(x, y, w, b):\n",
    "    # Forward pass\n",
    "    y_bar = jax.nn.sigmoid(jnp.dot(w, x.T) + b)\n",
    "    # Error computation\n",
    "    error = jnp.sum((y_bar - y) ** 2)\n",
    "    return error\n",
    "# Gradient of the loss\n",
    "grad_loss_function = jit(grad(loss_function, argnums=[2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can now define the main training loop, which is almost exactly similar to the previously defined one minus the gradient computation operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6639003ae5fc4fc59e0b710371f94029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'0b435737-06a3-42f5-9bf5-0b0c291a92d3': {'version"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update loop\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    \n",
    "    ######################\n",
    "    # Solution \n",
    "    gradients = grad_loss_function(x_jax, y_jax, weights, bias)\n",
    "    weights = weights - eta * gradients[0]\n",
    "    bias = bias - eta * gradients[1]\n",
    "    ######################\n",
    "    weights_history = weights_history.at[i + 1].set(weights[0])\n",
    "    bias_history = bias_history.at[i + 1].set(bias[0])\n",
    "    \n",
    "    if (verbose):\n",
    "        print('%2d. error = %f, weights = %f, %f, %f' % (i, np.sum(np.abs(error)) / n_observations, bias[0, 0], weights[0, 0], weights[0, 1]))\n",
    "plot = center_plot(\n",
    "    scatter_boundary(\n",
    "        np.array(x_inputs), \n",
    "        np.array(y_class), \n",
    "        np.array(weights_history), \n",
    "        np.array(bias_history), \n",
    "        i + 1)\n",
    "    )\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-layer networks\n",
    "\n",
    "In the following, we define the overall architecture of the exercise to fill. The goal is to define a more advanced problem \n",
    "\n",
    "### 2-layer XOR problem\n",
    "\n",
    "In most cases, classification problems are far from being linear. Therefore, we need more advanced methods to be able to compute non-linear class boundaries. The advantage of neural networks is that the same principle can be applied in a *layer-wise* fashion. This allows to further discriminate the space in sub-regions (as seen in the course). We will try to implement the 2-layer *perceptron* that can provide a solution to the infamous XOR problem. The idea is now to have the output of the first neurons to be connected to a set of other neurons. Therefore, if we take back our previous formulation, we have the same output for the first neuron(s) $y$, that we will now term as $y^{(1)}$. Then, we feed these outputs to a second layer of neurons, which gives\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "y^{(2)}=\\sigma\\left(\\sum_{i = 1}^{n}w_{i}.y^{(1)}_{i} + b\\right)\n",
    "\\end{equation}\n",
    "$$  \n",
    "\n",
    "Finally, we will rely on the same loss $\\mathcal{L_{D}}$ as in the previous exercise, but the outputs used are $y^{(2)}$ instead of $y$. As in the previous case, we now need to compute the derivatives of the weights and biases for several layers . However, you should see that some form of generalization might be possible for any number of layer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Exercise (course)\n",
    ">   1. Perform the derivatives for the last layer specifically\n",
    ">   2. Define a generalized derivative for any previous layer\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct the prototypical set of XOR values by using the following code (note that this is the most simple case, but still this is typically a problem that cannot be solved by a _linear classifier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90afd8be4f2c410599ea658ad47a7c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'a4786845-c01e-4ad7-8c37-2082df2f4884': {'version"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input patterns\n",
    "x_inputs = np.array([[-1, -1],[-1,  1],[1, -1],[1,  1]])\n",
    "# Corresponding classes\n",
    "y_class = np.array([0, 1, 1, 0])                        \n",
    "# Initialize based on their sizes\n",
    "n_inputs = x_inputs.shape[0]\n",
    "n_outputs = 1\n",
    "# Plot the XOR problem\n",
    "plot = center_plot(scatter_classes(x_inputs, y_class, title = \"XOR classification\"))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Observing the problem interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a840e89e4d14a369266973c7081f256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'6bf43b71-2584-4d7b-adb7-b6cfd8446d12': {'version"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cml.tasks import ClassificationLinear, ClassificationXOR\n",
    "explorer = ClassificationXOR()\n",
    "explorer.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem with the `scikit-learn` library\n",
    "\n",
    "As a side note, and as discussed in the previous course, there is obviously a lot of libraries that can perform the training of such networks for you directly, without understanding what is exactly going on behind the scene. A quite extensive library is `scikit-learn`, which contains already coded models and learning procedure, that will allow us to _learn_ the parameters of this unknown function.\n",
    "\n",
    "Here we will use a `MLPClassifier` model to perfom classification on standardized features that we rescale through the `LinearRegression` and that this polynomial should be of degree 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Create the MLP classifier\n",
    "classifier = MLPClassifier(alpha=1, max_iter=1000)\n",
    "# Standardize the input features\n",
    "clf = make_pipeline(StandardScaler(), classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now based on this model definition, training it can be performed with a single line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cml.data import xor_separation\n",
    "# Generate a XOR dataset\n",
    "x_inputs, y_classes = xor_separation(500, 0.1)\n",
    "# Train the MLP model\n",
    "clf.fit(x_inputs, y_classes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-layer implementation\n",
    "\n",
    "In this exercise, we will implement the XOR classification resolution using NumPy and JAX. This classification problem cannot be solved with a simple linear classifier. Hence, we will need to use at least a 2-layer network. The minimal set of variables that will be used by your code should be the following.\n",
    "\n",
    "```Python\n",
    "x_inputs          # 2 x n matrix of random points\n",
    "y_class           # classes of the patterns \n",
    "n_hidden          # Number of hidden units\n",
    "eta               # Learning rate parameter\n",
    "momentum          # Momentum parameter (bonus)\n",
    "weights1          # 1st layer weights\n",
    "weights2          # 2nd layer weights\n",
    "mse_limit         # Sum-squared error limit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hidden units\n",
    "n_hidden = 2\n",
    "# Learning rate parameter\n",
    "eta = 0.005\n",
    "# Momentum parameter\n",
    "momentum = 0.1\n",
    "# Sum-squared error limit\n",
    "mse_limit = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1 - 2-layers XOR classification\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> To complete this exercise, you will need to have a basic understanding of NumPy and JAX. You can use the resources provided in the previous exercises to learn more about these libraries.\n",
    "\n",
    "We help you out by first defining the XOR classification problem to solve (and outlining some basic properties)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cml.data import xor_separation\n",
    "# Definition of our data properties\n",
    "n_observations = 500\n",
    "noise_factor = 0.1\n",
    "# Properties of our problem\n",
    "n_input = 2\n",
    "n_output = 1\n",
    "# Generate a XOR dataset\n",
    "x_inputs, y_classes = xor_separation(n_observations, noise_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also show some potential implementation of the **initialization scheme**. Note that you can later try to replace this naive implementation by some more refined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st layer weights\n",
    "weights1 = (np.random.randn(n_hidden, n_input) * 0.01)\n",
    "# 2nd layer weights\n",
    "weights2 = (np.random.randn(n_output, n_hidden) * 0.01)\n",
    "# 1st layer biases\n",
    "bias1 = (np.random.randn(n_hidden, 1) * 0.01)\n",
    "# 2nd layer biases\n",
    "bias2 = (np.random.randn(n_output, 1) * 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.1 - Implement 2-layer XOR classification with NumPy\n",
    "\n",
    "> 1. Update the forward propagation and error computation\n",
    "> 2. Update the back-propagation part to learn the weights of both layers.\n",
    "> 3. Run the learning and check your network results\n",
    "  \n",
    "*For optional questions, please look at the end of this exercise's code boxes for more information*\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = y_classes.reshape((len(y_classes),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_inputs[:,0],x_inputs[:,1],c=y_classes)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "def dsigmoid(t):\n",
    "    return sigmoid(t)*(1-sigmoid(t))\n",
    "def forward(x,w1,w2,b1,b2):\n",
    "    x2 = sigmoid(w1@x.T + b1).T\n",
    "    return sigmoid(w2@x2.T + b2).T\n",
    "\n",
    "def loss(x,y,w1,w2,b1,b2):\n",
    "    y_bar = forward(x,w1,w2,b1,b2)\n",
    "    return ((y-y_bar)**2).sum()\n",
    "\n",
    "def gradient_loss(x,y,w1,w2,b1,b2):\n",
    "    n = len(y)\n",
    "    \n",
    "\n",
    "    o1 = (w1@x.T + b1).T\n",
    "    y1 = sigmoid(o1)\n",
    "    o2 = (w2@y1.T + b2).T\n",
    "    y2 = sigmoid(o2)\n",
    "\n",
    "    # delta2 = dsigmoid(o2) * (y2-y)\n",
    "    # delta1 = dsigmoid(o1) * (weights2 * delta2).sum()\n",
    "    # dw2 = delta2*y1\n",
    "    # print(delta2.shape,x.shape)\n",
    "    # dw1 = delta1*x\n",
    "    # db1 = delta1\n",
    "    # db2 = delta2\n",
    "\n",
    "    dldy2 = 2*(y-y2) #(496,1)\n",
    "    dy2do2 = dsigmoid(o2) #(496,1)\n",
    "    do2dw2 = y1 #(496,2)\n",
    "    do2dy1 = w2 #(1,2)\n",
    "    do2db2 = 1\n",
    "    dy1do1 = dsigmoid(o1) #(496,2)\n",
    "    do1dw1 = x.T #(496,2)\n",
    "    do1dx = w1 #(2,2)\n",
    "    do1db1 = 1  \n",
    "\n",
    "    #To make sure the dimensions are correct\n",
    "    dldw2 = np.zeros((n,1,2)) \n",
    "    dldb2 = np.zeros((n,1,1))\n",
    "    dlw1 = np.zeros((n,2,2))\n",
    "    dlb1 = np.zeros((n,2,1))\n",
    "\n",
    "    dldw2+= dldy2 * dy2do2 * do2dw2 #(496,1,2)\n",
    "    dldb2+= dldy2 * dy2do2 * do2db2 #(496,1,1)\n",
    "    dlw1+= dldy2 * dy2do2 * do2dy1 * dy1do1 * do1dw1 #(496,2,2)\n",
    "    dlb1+= dldy2 * dy2do2 * do2dy1 * dy1do1 * do1db1 #(496,2,1)\n",
    "\n",
    "    print(dldw2.shape,dldb2.shape,dlw1.shape,dlb1.shape)\n",
    "\n",
    "    #return dw1.sum(axis=0),dw2.sum(axis=0),db1.sum(axis=0),db2.sum(axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mul got incompatible shapes for broadcasting: (496, 1), (2, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\02_neural_networks.ipynb Cell 48\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y145sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dw1,dw2,db1,db2 \u001b[39m=\u001b[39m gradient_loss(x_inputs,y_classes,weights1,weights2,bias1,bias2)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y145sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dw1\n",
      "\u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\02_neural_networks.ipynb Cell 48\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y145sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m dldw2\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dldy2 \u001b[39m*\u001b[39m dy2do2 \u001b[39m*\u001b[39m do2dw2 \u001b[39m#(496,1,2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y145sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m dldb2\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dldy2 \u001b[39m*\u001b[39m dy2do2 \u001b[39m*\u001b[39m do2db2 \u001b[39m#(496,1,1)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y145sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m dlw1\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dldy2 \u001b[39m*\u001b[39;49m dy2do2 \u001b[39m*\u001b[39;49m do2dy1\u001b[39m.\u001b[39;49mT \u001b[39m*\u001b[39m dy1do1\u001b[39m.\u001b[39mT \u001b[39m*\u001b[39m do1dw1\u001b[39m.\u001b[39mT \u001b[39m#(496,2,2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y145sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m dlb1\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dldy2 \u001b[39m*\u001b[39m dy2do2 \u001b[39m*\u001b[39m do2dy1 \u001b[39m*\u001b[39m dy1do1 \u001b[39m*\u001b[39m do1db1 \u001b[39m#(496,2,1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y145sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(dldw2\u001b[39m.\u001b[39mshape,dldb2\u001b[39m.\u001b[39mshape,dlw1\u001b[39m.\u001b[39mshape,dlb1\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:256\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    254\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[0;32m    255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[1;32m--> 256\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    257\u001b[0m \u001b[39m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(other) \u001b[39min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\jax\\_src\\numpy\\ufuncs.py:97\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(x1, x2, \u001b[39m/\u001b[39m):\n\u001b[0;32m     96\u001b[0m   x1, x2 \u001b[39m=\u001b[39m promote_args(numpy_fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, x1, x2)\n\u001b[1;32m---> 97\u001b[0m   \u001b[39mreturn\u001b[39;00m lax_fn(x1, x2) \u001b[39mif\u001b[39;00m x1\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mbool_ \u001b[39melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "    \u001b[1;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\jax\\_src\\lax\\lax.py:1591\u001b[0m, in \u001b[0;36mbroadcasting_shape_rule\u001b[1;34m(name, *avals)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       result_shape\u001b[39m.\u001b[39mappend(non_1s[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1591\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m got incompatible shapes for broadcasting: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1592\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m,\u001b[39m \u001b[39m\u001b[39mmap\u001b[39m(\u001b[39mtuple\u001b[39m,\u001b[39m \u001b[39mshapes)))\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1594\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(result_shape)\n",
      "\u001b[1;31mTypeError\u001b[0m: mul got incompatible shapes for broadcasting: (496, 1), (2, 1)."
     ]
    }
   ],
   "source": [
    "dw1,dw2,db1,db2 = gradient_loss(x_inputs,y_classes,weights1,weights2,bias1,bias2)\n",
    "dw1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.2 - Implement XOR classification with JAX\n",
    "\n",
    "> 1. Perform the same implementation as previously with JAX\n",
    "> 2. Implement gradient descent to optimize the weights and bias.\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.3 - Understanding properties of our implementation\n",
    "\n",
    "> 4. Perform multiple re-runs of the learning procedure (re-launching with different initializations)\n",
    ">     1. What observations can you make on the learning process?\n",
    ">     2. What happens if you initialize all weights to zeros?\n",
    ">     3. Change your initialization and regularization scheme\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Going further\n",
    "\n",
    "> The following set of questions are optionnal addendum to your previous code that allow to understand more in-depth properties about _regularization_ both for neural networks and optimization in general.\n",
    "\n",
    "> 1. (Optional) Implement the *weight decay* constraint in your network.\n",
    "> 2. (Optional) Add the *momentum* to the learning procedure.\n",
    "\n",
    "> *Weight decay* constraint\n",
    "> As nothing constrains the weights in the network, we can note that usually all weights vector given a multiplicative factor might be equivalent, which can stall the learning (and lead to exploding weights). The *weight decay* allows to regularize the learning by penalizing weights with a too wide amplitude. The idea is to add this constraint as a term to the final loss (which leads to an indirect \"pressure\" on the learning process. Therefore, the final loss will be defined as\n",
    "> $$\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_{final}=\\mathcal{L_D} + \\lambda \\sum_{l} \\sum_{i} \\sum_{j} \\left( W_{ij}^{l} \\right)^{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "> where the parameter $\\lambda$ controls the relative importance of the two terms.\n",
    "\n",
    "> *Momentum* in learning\n",
    "> Usually, in complex problems, the gradient can be very noisy and, therefore, the learning might oscillate widely. In order to reduce this problem, we can *smooth* the different gradient updates by retaining the values of the gradient at each iteration and then performing an update based on the latest gradient $\\delta_{i}^{t}$ and the gradient at the previous iteration $\\delta_{i}^{t-1}$. Therefore, a gradient update is applied as\n",
    "> $$\n",
    "\\begin{equation}\n",
    "\\delta_{final}^{t} = \\delta_{i}^{t} + m.\\delta_{i}^{t-1}\n",
    "\\end{equation}\n",
    "$$\n",
    "> with $m$ the momentum parameter, which control the amount of gradient smoothing.\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 3-layer audio classification\n",
    "\n",
    "Once again, note that the following paragraph and subsequent questions are _optional_ but should be a quite simple extension of our previous work on 2-layer networks. If you struggle with the data import mechanisms, you can look down at the PyTorch section (with a **mandatory exercise**) that will provide base code for this aspect. \n",
    "\n",
    "Finally, we will attack a complete audio classification problem and try to perform neural network learning on a set of audio files. The data structure will be the same as the one used for parts 1 and 2. As discussed during the courses, even though a 2-layer neural network can provide non-linear boundaries, it can not perform \"holes\" inside those regions. In order to obtain an improved classification, we will now rely on a 3-layer neural network. The modification to the code of section 3.2 should be minimal, as the back-propagation will be similar for the new layer as one of the two others. We do not develop the math here as it is simply a re-application of the previous rules with an additional layer (which derivatives you should have generalized in the previous exercise).  \n",
    "\n",
    "However, up until now, we only performed *binary classification* problems, but this time we need to obtain a decision rule for multiple classes. Therefore, we cannot rely on simply computing the distance between desired patterns and the obtained binary value. The idea here is to rely on the *softmax regression*, by considering classes as a vector of probabilities. The desired answers will therefore be considered as a set of *probabilities*, where the desired class is $1$ and the others are $0$ (called *one-hot* representation). Then, the cost function will rely on the softmax formulation\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathcal{L_D}(\\theta) = - \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k} 1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_{j}^{T} x^{(i)}}}{\\sum_{l=1}^{k} e^{ \\theta_{l}^{T} x^{(i)} }}  \\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Therefore, we compute the output of the softmax by taking \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "p(y^{(i)} = j | x^{(i)}; \\theta) = \\frac{e^{\\theta_{j}^{T} x^{(i)}}}{\\sum_{l=1}^{k} e^{ \\theta_{l}^{T} x^{(i)}} }\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "By taking derivatives, we can show that the gradient of the softmax layer is\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\nabla_{\\theta_{j}} \\mathcal{L_D}(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} \\left( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j \\mid x^{(i)}, \\theta) \\right) \\right]}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweet activation functions\n",
    "\n",
    "As discussed in the course, the interest of stacking layers is that there is an _activation function_, which allows non-linear interactions between the dimensions (and avoids to only compute a single huge affine transform). Although the `sigmoid` function has been historically the most used, there has been some large developments since. Notably the `ReLU` (Rectified Linear Unit) is one of the major difference in modern networks (we will see more about that in a later course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the Sigmoid activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# Derivative\n",
    "def dsigmoid(a):\n",
    "    return a * (1.0 - a)\n",
    "# Function for computing the ReLU activation\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "# Derivative\n",
    "def drelu(x):\n",
    "    if (x < 0):\n",
    "        return 0\n",
    "    return 1\n",
    "# Function for computing the Tanh activation\n",
    "def tanh(x):\n",
    "    return np.tanh(x);\n",
    "# Derivative\n",
    "def dtanh(x): \n",
    "    return np.cosh(x) ^ -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we plot some simple examples of what these activation functions look like. You can try to rely on these functions in your previous training code and witness the differences in training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "unexpected attribute 'style' to Div, similar attributes are styles, stylesheets or syncable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\02_neural_networks.ipynb Cell 55\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y105sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     cur_plot\u001b[39m.\u001b[39mline(x, func(x), color\u001b[39m=\u001b[39mcolor, line_width\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y105sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     plots\u001b[39m.\u001b[39mappend(cur_plot)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y105sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m plot \u001b[39m=\u001b[39m center_plot(column(Div(text \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mDifferent activation functions\u001b[39;49m\u001b[39m\"\u001b[39;49m, style\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mfont-size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39m250\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m'\u001b[39;49m}), row(\u001b[39m*\u001b[39mplots)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lxqse/Documents/ATIAM%20ML/creative_ml/02_neural_networks.ipynb#Y105sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plot\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\models\\widgets\\markups.py:107\u001b[0m, in \u001b[0;36mDiv.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\models\\widgets\\markups.py:63\u001b[0m, in \u001b[0;36mMarkup.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\models\\widgets\\widget.py:56\u001b[0m, in \u001b[0;36mWidget.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\models\\layouts.py:97\u001b[0m, in \u001b[0;36mLayoutDOM.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\models\\ui\\ui_element.py:61\u001b[0m, in \u001b[0;36mUIElement.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\model\\model.py:110\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    108\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minitializing \u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not allowed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 110\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    111\u001b[0m default_theme\u001b[39m.\u001b[39mapply_to_model(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\core\\has_props.py:298\u001b[0m, in \u001b[0;36mHasProps.__init__\u001b[1;34m(self, **properties)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m Undefined \u001b[39mor\u001b[39;00m value \u001b[39mis\u001b[39;00m Intrinsic:\n\u001b[0;32m    297\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39msetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[0;32m    300\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproperties() \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(properties\u001b[39m.\u001b[39mkeys()):\n\u001b[0;32m    301\u001b[0m     desc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlookup(name)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\core\\has_props.py:333\u001b[0m, in \u001b[0;36mHasProps.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(descriptor, \u001b[39mproperty\u001b[39m): \u001b[39m# Python property\u001b[39;00m\n\u001b[0;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(name, value)\n\u001b[1;32m--> 333\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_attribute_error_with_matches(name, properties)\n",
      "File \u001b[1;32mc:\\Users\\lxqse\\Documents\\ATIAM ML\\creative_ml\\venv310\\lib\\site-packages\\bokeh\\core\\has_props.py:368\u001b[0m, in \u001b[0;36mHasProps._raise_attribute_error_with_matches\u001b[1;34m(self, name, properties)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m matches:\n\u001b[0;32m    366\u001b[0m     matches, text \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(properties), \u001b[39m\"\u001b[39m\u001b[39mpossible\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 368\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munexpected attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m attributes are \u001b[39m\u001b[39m{\u001b[39;00mnice_join(matches)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: unexpected attribute 'style' to Div, similar attributes are styles, stylesheets or syncable"
     ]
    }
   ],
   "source": [
    "from bokeh.models import Div\n",
    "from bokeh.layouts import column, row\n",
    "from cml.plot import cml_figure\n",
    "# Functions to\n",
    "funcs = [('Sigmoid',sigmoid,'red'), ('Tanh',tanh,'orange'), ('ReLU',relu,'yellow')]\n",
    "# Generating the x axis\n",
    "x = np.linspace(-5, 5, 100)\n",
    "plots = []\n",
    "for (name, func, color) in funcs:\n",
    "    cur_plot = cml_figure(plot_width=400, plot_height=250, title=name)\n",
    "    cur_plot.line(x, func(x), color=color, line_width=4)\n",
    "    plots.append(cur_plot)\n",
    "plot = center_plot(column(Div(text = \"Different activation functions\", style={'font-size': '250%'}), row(*plots)))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the whole network from scratch\n",
    "\n",
    "You should now have all the tools necessary to apply neural networks from scratch to a more complex problem. In the following exercise, we simply removed any guideline code, and you need to code all the procedure for training a NN and **apply it to audio data**. You will use the spectral features discussed in the previous exercise as an input.\n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Going further **(optional exercise) **\n",
    "\n",
    ">  1. Based on the previous neural network, upgrade the code to a 3-layer neural network\n",
    ">  2. Implement the *softmax regression* on top of your 3-layer network\n",
    ">  3. Use the provided code to perform classification on a pre-defined set of features\n",
    ">  4. As previously, change the set of features to assess their different accuracies\n",
    ">  5. Evaluate the neural network accuracy for all features combinations\n",
    ">  6. What happens if the learning rate is too large ? What is this phenomenon ?\n",
    ">  7. Perform a more advanced visualization of the learning process.\n",
    "  \n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `Pytorch` to enjoy life\n",
    "\n",
    "Up to now, we have been writing every operations by ourselves (in order to better understand the mathematics behind NN). However, there exists of course some simplifying libraries that provide large simplifications to this question.\n",
    "\n",
    "One of the most powerful and complete library of this sort is `Pytorch`, which has been developed for several years (even prior to the recent boom of deep learning). `Pytorch` provides a large set of pre-coded layers, but also **computational graphs** and **autograd**, which are very powerful paradigms allowing to define complex operators and automatically taking derivatives.\n",
    "\n",
    "## An (extremely) fast and dirty introduction to `Pytorch`\n",
    "\n",
    "PyTorch is a popular open-source deep learning framework based on the Torch library. It is primarily developed by Facebook AI research team, and it provides a simple and efficient way to build deep learning models. In this extremely short crash course, we will cover the basics of PyTorch, including:\n",
    "\n",
    "* Tensors\n",
    "* Automatic differentiation\n",
    "* Neural networks\n",
    "* Training a neural network on a dataset\n",
    "\n",
    "For a complete tutorial on PyTorch, please check out the [official PyTorch documentation](https://pytorch.org/tutorials/). This tutorial covers a wide range of topics, including the basics of PyTorch, building and training neural networks, working with data and dataloaders, and deploying models to production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "At its core, PyTorch is all about tensors. A tensor is a generalization of vectors and matrices to an arbitrary number of dimensions. A scalar is a 0-dimensional tensor, a vector is a 1-dimensional tensor, and a matrix is a 2-dimensional tensor.\n",
    "\n",
    "#### Creating Tensors\n",
    "We can create a PyTorch tensor from a Python list or a NumPy array using the `torch.tensor()` function, but also tensors of a specific size and/or with all zeros or all ones using the `torch.zeros()` and `torch.ones()` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# create a tensor from a Python list\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x)\n",
    "# create a tensor from a NumPy array\n",
    "y = torch.tensor(np.array([[1, 2], [3, 4]]))\n",
    "print(y)\n",
    "# create a 2x3 tensor of zeros\n",
    "z = torch.zeros((2, 3))\n",
    "print(z)\n",
    "# create a 3x2 tensor of ones\n",
    "w = torch.ones((3, 2))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor operations\n",
    "\n",
    "PyTorch tensors support a wide range of operations, including arithmetic operations like addition, subtraction, multiplication, and division, as well as more advanced operations like matrix multiplication, element-wise multiplication, and concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6,  8, 10, 12])\n",
      "tensor([ 5, 12, 21, 32])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# create two tensors\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "y = torch.tensor([5, 6, 7, 8])\n",
    "# add the two tensors\n",
    "z = x + y\n",
    "print(z)\n",
    "# element-wise multiplication\n",
    "w = x * y\n",
    "print(w)\n",
    "# matrix multiplication\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "c = torch.matmul(a, b)\n",
    "print(c)\n",
    "# concatenation\n",
    "d = torch.cat((a, b), dim=1)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic differentiation\n",
    "\n",
    "The core of PyTorch is the autograd package. It provides automatic differentiation for all operations on Tensors.\n",
    "\n",
    "PyTorch's autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backpropagation is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "To compute gradients, the `requires_grad` property of Tensors needs to `True` (which is the case by default). This tells PyTorch to track all operations on the Tensor. You can then call `.backward()` on a Tensor to compute the gradients with respect to that Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = 2*x**2 + 3*x - 1\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our network\n",
    "\n",
    "When building neural networks we frequently think of arranging the computation into layers, some of which have learnable parameters which will be optimized during learning. In `PyTorch`, the `nn` package provides higher-level abstractions over raw computational graphs that are useful for building neural networks. The `nn` package defines a set of `Modules`, which are roughly equivalent to neural network layers. A `Module` receives input `Tensors` and computes output `Tensors`, but may also hold internal state such as `Tensors` containing learnable parameters. The nn package also defines a set of useful loss functions that are commonly used when training neural networks.\n",
    "\n",
    "In the following example, we use the `nn` package to show how easy it is to instantiate our previous three-layers network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Define the input dimensions\n",
    "in_size = 1000\n",
    "# Number of neurons in a layer\n",
    "hidden_size = 100\n",
    "# Output (target) dimension\n",
    "output_size = 10\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_size, hidden_size),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hidden_size, hidden_size),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(hidden_size, output_size),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the network\n",
    "\n",
    "Up to this point we have updated the weights of our models by manually performing the gradient descent algorithm (changing the parameters vectors). Although this is not a huge burden for simple optimization algorithms like stochastic gradient descent, in practice we often train neural networks using more sophisticated optimizers like AdaGrad, RMSProp or Adam (that we will see later in this course)\n",
    "\n",
    "The `optim` package in PyTorch abstracts the idea of an optimization algorithm and provides implementations of commonly used optimization algorithms, and greatly simplfies the training loop associated with training a neural network.\n",
    "\n",
    "For the sake of presentation we will use random inputs $\\mathbf{x}$ that should be matched with random outputs $\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(batch_size, in_size)\n",
    "y = torch.randn(batch_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example we optimize the model using the Adam algorithm provided by the `optim` package, based on a `MSE` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(641.4479, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Learning rate\n",
    "learning_rate = 1e-4\n",
    "# Loss function that we will use\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "# Optimizer to fit the weights of the network\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(x)\n",
    "    # Compute the loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    # Before the backward pass, zero all of the network gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Backward pass: compute gradient of the loss with respect to parameters\n",
    "    loss.backward()\n",
    "    # Calling the step function to update the parameters\n",
    "    optimizer.step()\n",
    "print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Pytorch to classify audio\n",
    "\n",
    "Now that we know the main components of `Pytorch` to define and optimize networks, your assignement is to define a complete classification problem from audio data, by relying on this toolbox\n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.1 - Model and definition\n",
    "\n",
    ">   1. Use `Pytorch` to define a model for audio classification\n",
    ">   2. Import the audio features dataset and check that your model produces an output\n",
    "\n",
    "</div>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.2 - Training the model\n",
    "\n",
    ">   3. Write the optimization loop (think carefully about the _loss function_\n",
    ">   4. As previously, change the set of features to assess their different accuracies\n",
    ">   5. (Optional) Think of how you could use more complex features (time series, audio, STFT) to classify your data\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
